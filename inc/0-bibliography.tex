\begingroup 
\renewcommand{\section}[2]{\anonsection{Список используемых источников}}
\begin{thebibliography}{00}

\bibitem{statmt-book}
    Koehn P. Statistical machine translation. – Cambridge University Press, 2009.
    
\bibitem{alexnet}
    Krizhevsky A., Sutskever I., Hinton G. E. Imagenet classification with deep convolutional neural networks //Advances in neural information processing systems. – 2012. – С. 1097-1105.
\bibitem{imagenet-human}
    He K. et al. Delving deep into rectifiers: Surpassing human-level performance on imagenet classification //Proceedings of the IEEE international conference on computer vision. – 2015. – С. 1026-1034.
    
\bibitem{attn-all-need}
    Vaswani A. et al. Attention is all you need //Advances in neural information processing systems. – 2017. – С. 5998-6008.
    
\bibitem{attn-original}
    Bahdanau D., Cho K., Bengio Y. Neural machine translation by jointly learning to align and translate //arXiv preprint arXiv:1409.0473. – 2014.
    
\bibitem{lstm}
    Hochreiter S., Schmidhuber J. Long short-term memory //Neural computation. – 1997. – Т. 9. – №. 8. – С. 1735-1780.
    
\bibitem{gru}
    Chung J. et al. Empirical evaluation of gated recurrent neural networks on sequence modeling //arXiv preprint arXiv:1412.3555. – 2014.
    
\bibitem{encoder-decoder}
    Sutskever I., Vinyals O., Le Q. V. Sequence to sequence learning with neural networks //Advances in neural information processing systems. – 2014. – С. 3104-3112.
    
\bibitem{glue}
    Wang A. et al. Glue: A multi-task benchmark and analysis platform for natural language understanding //arXiv preprint arXiv:1804.07461. – 2018.

\end{thebibliography}
\endgroup

\clearpage
